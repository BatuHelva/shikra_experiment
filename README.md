<p align="center">
  <a href="#">
<img src="./assets/logo.png" alt="Logo" width="130"></a>
  <h4 align="center"><font color="#966661">Shikra</font>: Unleashing Multimodal LLMâ€™s Referential Dialogue Magic</h4>
  <p align="center">
    <a href='https://github.com/shikras/shikra'><img src='https://img.shields.io/badge/Project-Page-Green'></a>
    <a href='#'><img src='https://img.shields.io/badge/Paper-Arxiv-red'></a>
  </p>
</p>


***
<font color="#966661">**Shikra**</font>, an MLLM designed to kick off **referential dialogue** by excelling in spatial coordinate inputs/outputs in natural language, **without** additional vocabularies, position encoders, pre-/post-detection, or external plug-in models.

<p align="center"><img src="./assets/teaser.jpg" alt="teaser" width="300px" /></p>

## News
[06/28/2023] We will release our model before this weekend 07/02/2023.

## Examples

<img src="./assets/shikra_case_1.jpg" alt="shikra_case_1" style="zoom: 25%;" />
